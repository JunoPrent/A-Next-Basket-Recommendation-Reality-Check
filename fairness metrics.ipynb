{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### datasets and the threshold for each prediction file\n",
    "tafeng: [5,5,5,5,5], [7,7,7,7,7], [11,11,11,11,11] <br>\n",
    "dunnhumby: [7,7,7,7,7], [11,11,10,11,11], [19,19,18,19,19] <br>\n",
    "instacart: [11,11,11,11,11], [16,16,16,17,17], [26,26,27,28,26]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset:  dunnhumby\n",
      "prediction file number:  0\n",
      "minority user percentage for predictions:  0.050377274744784734\n",
      "\n",
      "prediction file number:  1\n",
      "minority user percentage for predictions:  0.05015534842432313\n",
      "\n",
      "prediction file number:  2\n",
      "minority user percentage for predictions:  0.05370616955170883\n",
      "\n",
      "prediction file number:  3\n",
      "minority user percentage for predictions:  0.050821127385707945\n",
      "\n",
      "prediction file number:  4\n",
      "minority user percentage for predictions:  0.0494895694629383\n",
      "\n",
      "average scores over all prediction files:\n",
      "(SPD)f-score@10 difference:  -0.03273933420128277\n",
      "(SPD)f-score@20 difference:  -0.03544482990526627\n",
      "(DI) f-score@10:  0.6089747651363522\n",
      "(DI) f-score@20:  0.533635074989412\n"
     ]
    }
   ],
   "source": [
    "# define dataset and which threshold to use for each prediction file\n",
    "dataset = \"dunnhumby\"\n",
    "print(\"dataset: \", dataset)\n",
    "thresholds = [7,7,7,7,7]\n",
    "\n",
    "#open future and history files\n",
    "with open(\"jsondata/\" + dataset + \"_future.json\") as f:\n",
    "    future = json.load(f)\n",
    "with open(\"jsondata/\" + dataset + \"_history.json\") as f:\n",
    "    history = json.load(f)\n",
    "\n",
    "SPD = [0, 0]\n",
    "DI = [0, 0]\n",
    "# determine SPD and DI for each predictcion file\n",
    "for i in range(5):\n",
    "    print(\"prediction file number: \", i)\n",
    "\n",
    "    f = open(\"methods/pred/\" + dataset + \"_attention_pred\" + str(i) + \".json\")\n",
    "    predictions = json.load(f)\n",
    "    purchase_numbers = []\n",
    "    test_key_list = []\n",
    "    for key in history:\n",
    "        # only take test users, sum lenght of each basket(without the [-1] baskets)\n",
    "        if key in predictions.keys():\n",
    "            test_key_list.append(key)\n",
    "            baskets = history[key][1:-1]\n",
    "            items = 0\n",
    "            for basket in baskets:\n",
    "                items += len(basket)\n",
    "\n",
    "            purchase_numbers.append(items)\n",
    "    \n",
    "        else:\n",
    "            continue\n",
    "\n",
    "    # create list of user ids who purchased less than 'threshold' items\n",
    "    minority_user_ids = np.where(np.array(purchase_numbers) < thresholds[i])[0]\n",
    "    for j in range(len(minority_user_ids)):\n",
    "        minority_user_ids[j] = test_key_list[minority_user_ids[j]]\n",
    "    \n",
    "    # some constants needed multiple times\n",
    "    test_size = len(predictions.keys())\n",
    "    minority_size = len(minority_user_ids)\n",
    "    majority_size = len(purchase_numbers) - minority_size   \n",
    "    \n",
    "    #print percentage as sanity check\n",
    "    percent = len(minority_user_ids) / test_size\n",
    "    print(\"minority user percentage for predictions: \", percent)\n",
    "\n",
    "    # metrics for minor and major groups\n",
    "    recall_10_minor, recall_20_minor, precision_10_minor, precision_20_minor = 0,0,0,0\n",
    "    recall_10_major, recall_20_major, precision_10_major, precision_20_major = 0,0,0,0\n",
    "    # loop through all predictions\n",
    "    for key in predictions:\n",
    "        predicted_basket = predictions[key]\n",
    "        ground_truth = future[key][1]\n",
    "        #minor users\n",
    "        if int(key) in minority_user_ids:\n",
    "            recall_10_minor += np.count_nonzero(np.isin(predicted_basket[:10], ground_truth)) / len(ground_truth)\n",
    "            recall_20_minor += np.count_nonzero(np.isin(predicted_basket[:20], ground_truth)) / len(ground_truth)\n",
    "            precision_10_minor += np.count_nonzero(np.isin(predicted_basket[:10], ground_truth)) / 10\n",
    "            precision_20_minor += np.count_nonzero(np.isin(predicted_basket[:20], ground_truth)) / 20\n",
    "        #major users\n",
    "        else:\n",
    "            recall_10_major += np.count_nonzero(np.isin(predicted_basket[:10], ground_truth)) / len(ground_truth)\n",
    "            recall_20_major += np.count_nonzero(np.isin(predicted_basket[:20], ground_truth)) / len(ground_truth)\n",
    "            precision_10_major += np.count_nonzero(np.isin(predicted_basket[:10], ground_truth)) / 10\n",
    "            precision_20_major += np.count_nonzero(np.isin(predicted_basket[:20], ground_truth)) / 20\n",
    "    \n",
    "    #take average for each metric over all users\n",
    "    recall_10_minor = recall_10_minor / minority_size\n",
    "    recall_20_minor = recall_20_minor / minority_size\n",
    "    precision_10_minor = precision_10_minor / minority_size\n",
    "    precision_20_minor = precision_20_minor / minority_size\n",
    "    recall_10_major = recall_10_major / majority_size\n",
    "    recall_20_major = recall_20_major / majority_size\n",
    "    precision_10_major = precision_10_major / majority_size\n",
    "    precision_20_major = precision_20_major / majority_size\n",
    "    \n",
    "    #determine f-scores for each group @10 and 20\n",
    "    f_score_10_minor = 2*(precision_10_minor*recall_10_minor)/(precision_10_minor+recall_10_minor)\n",
    "    f_score_20_minor = 2*(precision_20_minor*recall_20_minor)/(precision_20_minor+recall_20_minor)\n",
    "    f_score_10_major = 2*(precision_10_major*recall_10_major)/(precision_10_major+recall_10_major)\n",
    "    f_score_20_major = 2*(precision_20_major*recall_20_major)/(precision_20_major+recall_20_major)\n",
    "    \n",
    "    #determine fairness metrics\n",
    "    SPD[0] += f_score_10_minor - f_score_10_major\n",
    "    SPD[1] += f_score_20_minor - f_score_20_major\n",
    "    DI[0] += f_score_10_minor/f_score_10_major\n",
    "    DI[1] += f_score_20_minor/f_score_20_major\n",
    "    print(\"\")\n",
    "    \n",
    "#print results\n",
    "print(\"average scores over all prediction files:\")\n",
    "print(\"(SPD)f-score@10 difference: \", SPD[0]/5)\n",
    "print(\"(SPD)f-score@20 difference: \", SPD[1]/5)\n",
    "print(\"(DI) f-score@10: \", DI[0]/5)\n",
    "print(\"(DI) f-score@20: \", DI[1]/5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
